---
title: "NBA_hof_supervised"
output: html_document
date: "2024-05-03"
---

# 0. Prétraitement des données

```{r}
nba_hof_data = read.csv2("data_hof_award.csv", sep=",", dec=".", header=TRUE)
head(nba_hof_data)
str(nba_hof_data)
dim(nba_hof_data)
```
Par rapport à l'étude précédent pour les données de saison rookie rajoutées pour le clustering non supervisé, nous savons que la database possède des valeurs 'Nan' pour les colonnes '..._rookie_season'. On verifie également que d'autres colonnes ne possèdent pas de valeurs 'Nan' pour déterminer si on les supprime ou non. Les colonnes liées à l'année nba sont également présentent en plusieurs exemplaires ('season_x','season_year','year','season').

```{r}
# Compter les valeurs NaN pour chaque colonne dans la base de données data_hof_nba
nombre_nan_par_colonne <- colSums(is.na(nba_hof_data))

# Afficher le nombre de valeurs NaN pour chaque colonne
print(nombre_nan_par_colonne)
```


On va supprimer des données pas très pertinentes et que tous les joueurs ne possèdent pas vraiment comme les données des saisons rookie de tous les joueurs même si elles auraient pu donner une idée de si un rookie/joueur récent à la possibilité d'intégré le hall of fame.

```{r}
# Supprimer les colonnes de la base de données data_hof_nba
nba_hof_data <- subset(nba_hof_data, select = -c(pts_rookie_season, reb_rookie_season, ast_rookie_season,usg_pct_rookie_season, ts_pct_rookie_season, season_x,season,age,college,country,draft_year,draft_round,draft_number))

head(nba_hof_data)
```
Pour continuer, on va convertir les valeurs booléennes en entier ('True' == 1, 'False' == 0) pour la mise en place du clustering supervisé pour utiliser ces colonnes.

```{r}
# Identifier les colonnes avec des valeurs 'True' ou 'False'
colonnes_a_modifier <- sapply(nba_hof_data, function(col) any(col %in% c('True', 'False')))

# Remplacer 'True' par 1 et 'False' par 0 dans ces colonnes
nba_hof_data[, colonnes_a_modifier] <- lapply(nba_hof_data[, colonnes_a_modifier], function(col) {
  col <- ifelse(col == 'True', 1, ifelse(col == 'False', 0, col))
})

# Convertir les colonnes modifiées en type integer
nba_hof_data[, colonnes_a_modifier] <- lapply(nba_hof_data[, colonnes_a_modifier], as.integer)


head(nba_hof_data)
```
Le but de notre classification supervisée sera de pouvoir déterminer si un joueur est éligible ou non à l'accès au Hall of Fame (soit le Panthéon des joueurs NBA). Pour cela, nous étudierons les données des joueurs durant leur carrière respective. Il faut donc regrouper les données de chaque saison de manière logique pour chaque joueur. On aura à la fin, une ligne pour chaque joueur.

Avant ceci, pour justement pouvoir effectuer de manière logique pour la suite ce clustering supervisé, il faudra séparer les joueurs actuels que les joueurs ayant pris leur retraite/ou parti de la NBA. Ainsi on conservera des données de test pour voir si certains joueurs actuels on des possibilités plus ou moins faibles d'intégrer le Hall of Fame.

Ici, pour essayer de ne pas mal influencer, nous verifions les données de hall_of_fame de 5 joueurs récemment entrés au Hall of Fame en 2023 (pour les 4 des 5 testés, l'autre est récent aussi). Si la valeur 0 est présente au sein de la colonne hall_of_fame, il faut mettre ces 5 joueurs dans les données à tester. 
```{r}
# Supposons que votre base de données contient une colonne 'Nom' avec les noms des joueurs
tony_parker <- subset(nba_hof_data, player_name == "Tony Parker")
dwyane_wade <- subset(nba_hof_data, player_name == "Dwyane Wade")
dirk_nowitzki <- subset(nba_hof_data, player_name == "Dirk Nowitzki")
kobe_bryant <- subset(nba_hof_data, player_name == "Kobe Bryant")
pau_gasol <- subset(nba_hof_data, player_name == "Pau Gasol")
manu_ginobili <- subset(nba_hof_data, player_name == "Manu Ginobili")

# Afficher les informations sur Tony Parker
print(tony_parker)

# Afficher les informations sur Dwyane Wade
print(dwyane_wade)

# Afficher les informations sur Dirk Nowitzki
print(dirk_nowitzki)

# Afficher les informations sur Kobe Bryant
print(kobe_bryant)

# Afficher les informations sur Pau Gasol
print(pau_gasol)
```
Comme on peut le voir ici, les 4 joueurs ayant été inaugurés au Hall of Fame 2023 possèdent la valeur 0 pour la colonne associée. Donc il sera judicieux de les mettre dans la database à tester pour ne pas influencer de mauvaise manière le clustering.

Séparons notre database principale en 2 databases avec les anciens joueurs et les joueurs actuels/récemment retirés.

```{r}
# Identifier les joueurs dont l'année maximale est inférieure à 2018
joueurs_inferieurs_2018 <- subset(nba_hof_data, ave(season_year, player_name, FUN = max) < 2018)

# Identifier tous les joueurs
tous_les_joueurs <- unique(nba_hof_data$player_name)

# Identifier les joueurs parmi tous les joueurs qui ont des années supérieures ou égales à 2018
joueurs_superieurs_2018 <- subset(nba_hof_data, ave(season_year, player_name, FUN = max) >= 2018)

# Créer la base de données des joueurs dont l'année max est inférieure à 2018
data_old_player <- subset(nba_hof_data, player_name %in% joueurs_inferieurs_2018$player_name)

# Créer la base de données des joueurs dont l'année max est supérieure ou égale à 2018
data_recent_player <- subset(nba_hof_data, player_name %in% joueurs_superieurs_2018$player_name)

```

Vérifions vite fait

```{r}
head(data_old_player)
head(data_recent_player)

dim(data_old_player)
dim(data_recent_player)
```
Vérifions la présence des 5 joueurs au sein des bonnes databases.

```{r}
# Joueurs à vérifier
joueurs_a_verifier <- c("Tony Parker", "Dwyane Wade", "Dirk Nowitzki", "Pau Gasol", "Kobe Bryant")

# Vérification dans la base de données des joueurs dont l'année max est inférieure à 2018
verif_inferieure_2018 <- subset(data_old_player, player_name %in% joueurs_a_verifier)

# Vérification dans la base de données des joueurs dont l'année max est supérieure ou égale à 2018
verif_superieure_2018 <- subset(data_recent_player, player_name %in% joueurs_a_verifier)

# Affichage des résultats
print("Vérification dans la base de données des joueurs dont l'année max est inférieure à 2018 :")
print(verif_inferieure_2018)

print("Vérification dans la base de données des joueurs dont l'année max est supérieure ou égale à 2018 :")
print(verif_superieure_2018)

```
Comme vérifier antérieurement les joueurs récemment inaugurés au Hall of Fame sont dans la database à tester. Contrairement à l'autre qui est dans celle à utiliser comme souhaité.

Pour la classification supervisé on convertit les colonne str de manière judicieuse, (1 pour les joueurs ayant été champions nba l'année indiqué, pareil pour finalist et mvp_finals)

```{r}
# Pour data_old_player
data_old_player$nba_champion <- ifelse(data_old_player$team_abbreviation == data_old_player$nba_champion, 1, 0)
data_old_player$finalist <- ifelse(data_old_player$team_abbreviation == data_old_player$finalist, 1, 0)
data_old_player$mvp_finals <- ifelse(data_old_player$player_name == data_old_player$mvp_finals, 1, 0)

# Pour data_recent_player
data_recent_player$nba_champion <- ifelse(data_recent_player$team_abbreviation == data_recent_player$nba_champion, 1, 0)
data_recent_player$finalist <- ifelse(data_recent_player$team_abbreviation == data_recent_player$finalist, 1, 0)
data_recent_player$mvp_finals <- ifelse(data_recent_player$player_name == data_recent_player$mvp_finals, 1, 0)
```

On convertit en facteur les colonnes college et country pour pas de problème lors de la fusion selon les joueurs

```{r}
# Convertir les colonnes contenant les noms de pays et de collèges en facteurs s'ils sont identiques pour chaque joueur
# data_old_player$college <- as.factor(data_old_player$college)
# data_old_player$country <- as.factor(data_old_player$country)

# data_recent_player$college <- as.factor(data_recent_player$college)
# data_recent_player$country <- as.factor(data_recent_player$country)

```

On génère des databases selon le nom des joueurs avec les colonnes suivantes de summarise.

```{r}
# Chargement de la bibliothèque dplyr
library(dplyr)

# Regroupement des lignes par joueur et calcul de la moyenne pour certaines colonnes, addition pour d'autres
data_old_player_career <- data_old_player %>%
  group_by(player_name) %>%
  summarise(
    player_height = mean(player_height),
    player_weight = mean(player_weight),
    gp_career = sum(gp),
    gp_by_season = mean(gp),
    pts_career_avg = mean(pts),
    reb_career_avg = mean(reb),
    ast_career_avg = mean(ast),
    net_rating_career = mean(net_rating),
    oreb_pct_career = mean(oreb_pct),
    dreb_pct_career = mean(dreb_pct),
    usg_pct_career = mean(usg_pct),
    ts_pct_career = mean(ts_pct),
    ast_pct_career = mean(ast_pct),
    num_seasons = mean(num_seasons),
    hall_of_fame = max(hall_of_fame),
    indiv_awards = max(indiv_award),
    playoffs_career = sum(playoffs),
    nba_titles = sum(nba_champion),
    mvp_finals = sum(mvp_finals),
    finalist_career = sum(finalist)
  )

data_recent_player_career <- data_recent_player %>%
  group_by(player_name) %>%
  summarise(
    player_height = mean(player_height),
    player_weight = mean(player_weight),
    gp_career = sum(gp),
    gp_by_season = mean(gp),
    pts_career_avg = mean(pts),
    reb_career_avg = mean(reb),
    ast_career_avg = mean(ast),
    net_rating_career = mean(net_rating),
    oreb_pct_career = mean(oreb_pct),
    dreb_pct_career = mean(dreb_pct),
    usg_pct_career = mean(usg_pct),
    ts_pct_career = mean(ts_pct),
    ast_pct_career = mean(ast_pct),
    num_seasons = mean(num_seasons),
    hall_of_fame = max(hall_of_fame),
    indiv_awards = max(indiv_award),
    playoffs_career = sum(playoffs),
    nba_titles = sum(nba_champion),
    mvp_finals = sum(mvp_finals),
    finalist_career = sum(finalist)
  )

head(data_old_player_career)
head(data_recent_player_career)

dim(data_old_player_career)
dim(data_recent_player_career)
```
On peut constater la présence de duplicates, on va donc en conserver qu'une ligne pour chaque joueur ce qui est normal.

```{r}
# Supprimer les doublons de data_old_player_career
data_old_player_career <- distinct(data_old_player_career)

# Supprimer les doublons de data_recent_player_career
data_recent_player_career <- distinct(data_recent_player_career)

head(data_old_player_career)
head(data_recent_player_career)

dim(data_old_player_career)
dim(data_recent_player_career)
```
A noté que le facteur le plus perturbant de la mise en place de nos clustering non-supervisée et supervisé est tout simplement liée au fait que les données commence en 1996 et que les joueurs ayant été en NBA avant, n'ont tout simplement pas toutes leurs stats de toutes leurs saisons effectuées.

A part ce problème principale ne pouvant être régler que par l'ajout de ces valeurs antérieurs ce qui rendrait les bases de données complètes et sans biais possible.

Le traitement des données à l'air d'être réalisé correctement et on va pouvoir réalisé notre clustering supervisé pour le Hall of Fame.

```{r}
# Pour data_old_player_career
write.csv(data_old_player_career, "data_old_player_career.csv", row.names = FALSE)

# Pour data_recent_player_career
write.csv(data_recent_player_career, "data_recent_player_career.csv", row.names = FALSE)

```



# 1. Mise en place de la classification supervisée

Pour commencer pour éviter tout problème de type dans la mise en place de nos algorithmes de classification nous allons convertir les données qualitatives en 'factor' et les données 'int' en 'num'. A la suite de ça, nous regardons si nous possédons un jeu déséquilibré ou non (il l'est logiquement étant donné que l'entrée à ce mémorialest très prestigieux donc peu de joueur ont reçu cette gratification).

```{r}
data_past_NBA = read.csv2("data_old_player_career.csv", sep=",", dec=".", header=TRUE,row.names = 1)
data_present_NBA = read.csv2("data_recent_player_career.csv", sep=",", dec=".", header=TRUE,row.names = 1)

data_past_NBA$hall_of_fame <- ifelse(data_past_NBA$hall_of_fame == 1, "Yes", "No")
data_past_NBA$hall_of_fame <- as.factor(data_past_NBA$hall_of_fame)
data_past_NBA$indiv_awards <- as.factor(data_past_NBA$indiv_awards)

# Trouver les colonnes de type entier
int_columns <- sapply(data_past_NBA, is.integer)

# Convertir les colonnes de type entier en numérique
data_past_NBA[int_columns] <- lapply(data_past_NBA[int_columns], as.numeric)


head(data_past_NBA)
str(data_past_NBA)
table(data_past_NBA$hall_of_fame)
Hall_of_Fame_In = table(data_past_NBA$hall_of_fame)[2]/dim(data_past_NBA)[1]
Hall_of_Fame_In
Hall_of_Fame_Out = table(data_past_NBA$hall_of_fame)[1]/dim(data_past_NBA)[1]
Hall_of_Fame_Out
```
Après tout ceci effectué, on constate bien que le jeu de données est déséquilibré comme attendu ce qui nous force à devoir le rééquilibrer. Pour cela on va diviser notre jeu de données à utiliser en 2 (répartition (80-20)) avec des données d'entraînement et de test.

Création d'un échantillon test

```{r}
set.seed(1)
n <- nrow(data_past_NBA)
p <- ncol(data_past_NBA)-1
test.ratio <- .2 # ratio of test/train samples
n.test <- round(n*test.ratio)
n.test
tr <- sample(1:n,n.test)
data.test <- data_past_NBA[tr,]
data.train <- data_past_NBA[-tr,]
```
```{r}
# Répartition des données à tester
table(data.test$hall_of_fame)
Hall_of_Fame_In = table(data.test$hall_of_fame)[2]/dim(data.test)[1]
Hall_of_Fame_In
Hall_of_Fame_Out = table(data.test$hall_of_fame)[1]/dim(data.test)[1]
Hall_of_Fame_Out
```
```{r}
# Répartition des donneés à entraîner
table(data.train$hall_of_fame)
Hall_of_Fame_In = table(data.train$hall_of_fame)[2]/dim(data.train)[1]
Hall_of_Fame_In
Hall_of_Fame_Out = table(data.train$hall_of_fame)[1]/dim(data.train)[1]
Hall_of_Fame_Out
```

Ici, nous allons regarder le comportement qu'aurait une prédiction d'un nouveau joueur pour connaîter sa possible entrée au Hall of Fame.   

```{r}
library(randomForest)
fit_RF <- randomForest(hall_of_fame~.,data.train)
fit_RF
plot(fit_RF)
```
Représentation de l’erreur Out of Bag : Les données non utilisées dans les échantillons boostrap sont utilisées pour estimer l’erreur de classification. En noire, erreur de classification totale, en rouge et verte les erreurs de classification pour les 2 classes : vert pour la class HoF_In et rouge pour la class Hof_Out. Vérifier que l’erreur OOB pour la classe HoF_In est très élevée !

On conclut donc que la prédiciton de l'entrée au Hall of Fame de nos nouveaux joueurs sera quasiment toujours soldé par un refus sauf pour des cas d'exception plus restrictifs que ferait le Hall of Fame. Cela nous indique que nous pouvons pas appliquer d'algorithme de classification supervisée sur un tel jeu de données sans procédér à un rééquilibrage.

Ce que nous allons réalisé maintenant :

```{r}
library(DMwR)

data.train.balanced <- SMOTE(hall_of_fame ~., data.train)

table(data.train.balanced$hall_of_fame)
Hall_of_Fame_In = table(data.train.balanced$hall_of_fame)[2]/dim(data.train.balanced)[1]
Hall_of_Fame_In
Hall_of_Fame_Out = table(data.train.balanced$hall_of_fame)[1]/dim(data.train.balanced)[1]
Hall_of_Fame_Out
```
On regrade après le rééquilibrage de notre jeu de données entraîné avec les possibles prédictions qu'il pourrait faire avec randomForest comme précédemment :

```{r}
fit_RF <- randomForest(hall_of_fame~.,data.train.balanced)
fit_RF
plot(fit_RF)
```
On constate donc que les prédictions se feront de manière assez équitable avec certes l'erreur de classification des 'No' et totale plus élevé que la dernière fois (légèrement) mais pour ce qu'il s'agit de l'erreur de classification des 'Yes', cette erreur est beaucoup plus faible que l'ancienne de manière non négligeable comparé aux 2 autres erreurs. (tot -> noir, No -> rouge, Yes -> vert).

On regarde désormais les erreurs de prévisions de ce nouveau modèle 

```{r}
class_RF = predict(fit_RF,newdata = data.test,type="response")
```

```{r}
confusion_matrix = table(class_RF,data.test$hall_of_fame)
confusion_matrix
```
Taux d'erreur de prédictions pour chaque catégorie 'Yes' et 'No' (attendu : faible pour les prédictions 'No', élevé pour les prédictions 'Yes') 
```{r}
err_No = confusion_matrix[1,2]/(confusion_matrix[1,1]+confusion_matrix[1,2])
# Arrondir le taux d'erreur
err_No_rounded <- round(err_No, 3)

# Affichage du taux d'erreur arrondi
print(paste("Taux d'erreur de 'Non' prédits :", sprintf("%.3f", err_No_rounded)))

err_Yes = confusion_matrix[2,1]/(confusion_matrix[2,1]+confusion_matrix[2,2])
# Arrondir le taux d'erreur
err_Yes_rounded <- round(err_Yes, 3)

# Affichage du taux d'erreur arrondi
print(paste("Taux d'erreur de 'Yes' prédits :", sprintf("%.3f", err_Yes_rounded)))
```
Taux d'erreur de prédictions total
```{r}
err_tot = (confusion_matrix[1,2]+confusion_matrix[2,1])/(confusion_matrix[1,1]+confusion_matrix[1,2]+confusion_matrix[2,1]+confusion_matrix[2,2])
err_tot_rounded = round(err_tot, 3)

print(paste("Taux d'erreur total des prédictions :", sprintf("%.3f",err_tot_rounded)))
```

