---
title: "Projet analyse de données - NBA drafts"
author: "TRINH Nhat-nam, SOBCZYK Gabriel - MAIN4"
date: "2024-03-01"
output: html_document
---

# Prétrairement des données

```{r}
nba_drafts_data = read.csv2("all_seasons.csv", sep=",", dec=".", header=TRUE, row.names = 1)
head(nba_drafts_data)
str(nba_drafts_data)
dim(nba_drafts_data)
```

Résumé :

```{r}
summary(nba_drafts_data)
```

On enlève les lignes qui contiennent des données indéfinies.

```{r}
nba_drafts_data = na.omit(nba_drafts_data)
dim(nba_drafts_data)

````

## Agrégation pour l'ACP

Nous allons effectuer une ACP sur nos données afin d'étudier dans un premier temps la corrélation entre les variables. La question qu'on se pose principalement est : Est-ce que certaines caractéristiques (taille, poids) vont favoriser un style de jeu en particulier (plus d'assites, de rebonds ?).

```{r}
# On garde que les colonnes numériques mais on prend aussi les noms des joueurs
names_numes = names(which(sapply(nba_drafts_data, is.numeric)))
nba_drafts_data_study_1 = nba_drafts_data[,names_numes]
head(nba_drafts_data_study_1)
```
On fait une aggrégation en faisant la moyenne des valeurs numériques en rassemblant.
```{r}
nba_drafts_data_study_1 = aggregate(nba_drafts_data_study_1, by=list(nba_drafts_data$player_name), FUN=mean)
head(nba_drafts_data_study_1)
dim(nba_drafts_data_study_1)
```

# 1. ACP 

Nous prenons les variables qui sont liés à la performance et aux caractéristiques du joueur.

```{r}
nba_drafts_data_study_1 = nba_drafts_data_study_1[c("player_height", "player_weight", "pts", "reb", "ast", "oreb_pct", "dreb_pct", "ts_pct")]
head(nba_drafts_data_study_1)
```

Nous effectuons une ACP.

```{r}
library(FactoMineR)
ACP = PCA(nba_drafts_data_study_1)
plot.PCA(ACP, choix="varcor", select="cos2 0.6")
```

Nous voyons que oreb_pct (contribution des rebonds offensives) et ts_pct (pourcentage de panier mis) sont mal interprétées à cause des mesures du cos2 de la projection qui sont faibles donc nous allons l'enlever.

```{r}
ACP = PCA(nba_drafts_data_study_1[c("player_height", "player_weight", "pts", "reb", "ast","dreb_pct")])
plot.PCA(ACP)
```

On regarde les contributions cumulées des axes.

```{r}
barplot(cumsum(ACP$eig[,2]))
```

2 dimensions servent déjà à expliquer 80% des données.

Regardons le cercle de corrélation :

On voit que le premier axe correspond aux caractéristiques des joueurs : plus les individus ont des grandes caractéristiques, plus ils sont placés vers la droite dans le graphe de l'ACP. Ici, on voit particulièrement que la taille des joueurs NBA corrélère positivement avec leur poids ce qui semble assez logique pour des sportifs.

Le deuxième axe semble correspond aux performances du joueurs : on voit que les points et le nombre d'assistes et de rebond sont corrélés à cet axe.

Par conséquent, chaque cadre semble correspondre à un profil de joueur : les individus en haut à droite semble correspondre aux joueurs qui ont de très bonnes performances et caractéristiques. Les individus en bas à gauche semble correspondre aux joueurs qui ont de moins bonnes performances et caractéristiques.

Regardons les 50 individus les plus contributeurs dans l'ACP :

```{r}
plot(ACP, choix="ind", select="contrib 10")
```
On remarque que les joueurs les plus contributeurs sont situés dans les extrêmes. Essayons de voir quels sont ces joueurs.

```{r}
nba_drafts_data_study_1[c(404,1535, 2102, 1377),]
```



## ACP avec étude de draft

Ici, on cherche à savoir si la performance du joueur justifie le numéro de draft. La période de draft est effectué tous les ans donc nous allons seulement nous restreindre à une saison en particulière. En toute généralité, les joueurs draftés en premier sont généralement des joueurs prometteurs. Cette étude va permettre de savoir si les joueurs "méritent" leur numéro de draft.

On va étudier la saison 1998-99.
```{r}
nba_drafts_data_study_2 = nba_drafts_data[which(nba_drafts_data$season == "1998-99"),]
head(nba_drafts_data)
```

Il y a des joueurs qui peuvent être non draftés dont leurs numéros de drafts ne sont pas indiqués (NA) donc on va mettre -1 à la place.
```{r}
 nba_drafts_data_study_2$draft_round[which(is.na(nba_drafts_data_study_2$draft_round))] = -1
```

On considère le round de draft comme une variable supplémentaire pour voir le centre de gravité des groupes de drafts. On veut en effet voir comment sont regroupés ce qui sont draftés et ce qui ne le sont pas.
```{r}
ACP_2 = PCA(nba_drafts_data_study_2[c("player_height", "player_weight", "pts", "reb", "ast","dreb_pct", "draft_round")], quali.sup=7)
plot.PCA(ACP_2, select = "contrib 25")
```
On peut faire un coloriage pour voir exactement où sont les groupes de draft dans le graphique des individus.

```{r}
plot(ACP_2, choix="ind", habillage=7)
```
On voit que la plupart des joueurs draftés au 2ème round ont eu des mauvaises performances tandis qu'on peut trouver toute sorte de profil pour les joueurs draftés au premier round.


#2. Clustering sur les styles de jeu

## CAH
Ici, on va chercher à étudier s'il y a différents profils de joueurs : quels sont les styles de jeu présents ?

On va d'abord faire une classification CAH et estimer le nombre de classes optimale qui minimise la distance intra classe.

```{r}
# Extraction des données numériques
season_data = nba_drafts_data[which(nba_drafts_data$season == "1998-99"),]
season_data = season_data[c("player_height", "player_weight", "pts", "reb", "ast", "oreb_pct", "dreb_pct", "ts_pct")]

# CAH
distance = dist(season_data)
hc <- hclust(distance, method = "ward.D2")
plot(hc)
rect.hclust(hc, k = 4, border="blue")
```


On voit qu'on peut séparer en environ 4 classes d'invidividu.
```{r}
player_grps = cutree(hc, k=4) 
season_data_with_cah = cbind.data.frame(season_data, cluster = factor(player_grps))
dim(season_data_with_cah)
ACP_cah = PCA(season_data_with_cah, quali.sup=9)
plot(ACP_cah, choix="ind", habillage=9)
```
Ici, on voit que le cluster 1 définit déjà un groupe de joueurs avec des performances et des caractéristiques particuliers. Etudions les variables de l'ACP. On pourrait ici garder 2 axes comme l'ajout d'un 3ème axe ne va pas améliorer grandement l'explication des données.

```{r}
barplot(cumsum(ACP_cah$eig[,2]))
```



Regardons les caractéristiques des individus dans chaque cluster :

```{r}
stats_grps_cah = aggregate(season_data, by=list(player_grps), FUN=mean)
dim(stats_grps_cah)
stats_grps_cah
```





## K-means

Comparons avec l'algorithme de kmeans avec 4 centres et 1000 initialisations. 

```{r}
kmeans.result = kmeans(season_data, centers = 4, nstart=1000)
table(kmeans.result$cluster, player_grps)
```
On voit que ces 2 modèles des résultats très différents. Essayons de voir comment ces modèles séparent les joueurs.


```{r}
season_data_with_kmeans = cbind.data.frame(season_data, cluster = factor(kmeans.result$cluster))
dim(season_data_with_kmeans)
ACP_kmeans = PCA(season_data_with_kmeans, quali.sup=9)
```

Il faudrait ici garder 3 axes pour expliquer au moins 80% des données. 2 axes pourraient suffir avoir 70% des données.

Voici la répartition des clusters dans le graphe des individus :
```{r}
plot(ACP_kmeans, choix="ind", habillage=9)
```
On peut remarquer plusieurs choses :
- on voit que les clusters 1/3 et les clusters 2/4 sont séparés par le deuxième axe. Rappelons nous que l'axe 1 sépare les joueurs selon leur poids et
- les performances des joueurs ne semblent pas être un critère pour séparer les individus : on peut retrouver différents profils de joueurs dans l'ACP.



Même chose ici, on peut essayer de regarder la contribution des axes
```{r}
barplot(cumsum(ACP_kmeans$eig[,2]))
```





# Ajout de clusters supplémentaires 

Essayons d'ajouter des clusters pour voir si on peut voir des séparations au niveau de la performance des joueurs.

## CAH
```{r}
plot(hc)
rect.hclust(hc, k = 6, border="blue")
```
On refait une ACP avec un coloriage selon les clusters.

```{r}
player_grps2 = cutree(hc, k=6)
season_data_with_cah2 = cbind.data.frame(season_data, cluster = factor(player_grps2))
dim(season_data_with_cah2)
ACP_cah = PCA(season_data_with_cah2, quali.sup=9)
plot(ACP_cah, choix="ind", habillage=9)
```

Les cluters 1,2,5 et 6 semblent prendre en compte maintenant les performances des joueurs. On peut par contre trouver plusieurs profils dans les clusters 2 et 3 en terme de performances.


## K-means


```{r}
kmeans.result2 = kmeans(season_data, centers = 6, nstart=1000)
table(kmeans.result2$cluster, player_grps2)
```
On voit là encore de très grandes différences en terme de classification ce qui est normal car ces 2 modèles peuvent classifier différement les clusters.

```{r}
season_data_with_kmeans2 = cbind.data.frame(season_data, cluster = factor(kmeans.result2$cluster))
dim(season_data_with_kmeans2)
ACP_kmeans = PCA(season_data_with_kmeans2, quali.sup=9)
plot(ACP_kmeans, habillage=9, choix="ind")
```
On peut voir que les clusters sont répartis de la même manière que le CAH. Les clusters ne sont pas pris dans le même ordre.

Dans ce graphe, nous pouvons voir que le cluster 6 regroupe les joueurs ayant des bonnes performances et ayant des bonnes caractéristiques. Nous pouvons de cette manière interpréter les autres groupes.


# Retrait des colonnes pourcentages

Test pour voir si le retrait des  colonnes pourcentages pourraient améliorer la classification
```{r}
# # Données
# season_data = nba_drafts_data[which(nba_drafts_data$season == "1998-99"),]
# season_data = season_data[c("player_height", "player_weight", "pts", "reb", "ast")]
# 
# # CAH
# distance = dist(season_data)
# hc <- hclust(distance, method = "ward.D2")
# plot(hc)
# rect.hclust(hc, k = 6, border="blue")
# player_grps = cutree(hc, k=6)
# 
# # ACP
# season_data_with_cah = cbind.data.frame(season_data, cluster = factor(player_grps))
# dim(season_data_with_cah)
# ACP_cah = PCA(season_data_with_cah, quali.sup=6)
# plot(ACP_cah, habillage=6, choix="ind")
```
